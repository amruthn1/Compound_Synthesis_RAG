{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c19522e8",
   "metadata": {},
   "source": [
    "# Materials Science RAG Platform\n",
    "## CIF Generation - Property Prediction - Safety-Enforced Synthesis\n",
    "### Powered by Qwen2.5-7B, Qdrant, and Materials ML Models\n",
    "\n",
    "---\n",
    "\n",
    "**This notebook:**\n",
    "- Runs entirely in Google Colab\n",
    "- Uses A100 GPU if available\n",
    "- Implements real models (no mocks)\n",
    "- Enforces mandatory safety protocols\n",
    "- Complete materials discovery pipeline\n",
    "\n",
    "**All logic is in the shared pipeline backend.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf62e0",
   "metadata": {},
   "source": [
    "## Setup: Environment Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c51a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Detect environment\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ENVIRONMENT DETECTION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Running in Colab: {IN_COLAB}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Note: Will check GPU after installing dependencies\n",
    "if IN_COLAB:\n",
    "    print(\"⚠ GPU detection will be available after installing PyTorch\")\n",
    "else:\n",
    "    print(\"Running locally\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d22d68",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DEPENDENCY INSTALLATION - COLAB OPTIMIZED\n",
    "# ============================================================================\n",
    "# Using Qwen2.5-7B-Instruct with stable 4-bit quantization\n",
    "\n",
    "print(\"Step 1: Removing conflicting packages...\")\n",
    "!pip uninstall -y torch torchvision torchaudio transformers sentence-transformers huggingface-hub accelerate bitsandbytes tokenizers peft dgl -q 2>/dev/null\n",
    "\n",
    "print(\"\\nStep 2: Installing PyTorch with CUDA 12.1 (Colab default)...\")\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 -q\n",
    "\n",
    "print(\"\\nStep 3: Installing HuggingFace ecosystem (EXACT versions)...\")\n",
    "!pip install huggingface-hub==0.24.0 --no-deps -q\n",
    "!pip install tokenizers==0.19.1 --no-deps -q\n",
    "!pip install transformers==4.43.2 --no-deps -q\n",
    "!pip install sentence-transformers==2.5.1 --no-deps -q\n",
    "\n",
    "print(\"\\nStep 4: Installing missing dependencies for HuggingFace packages...\")\n",
    "!pip install -q filelock fsspec packaging pyyaml regex requests tqdm typing-extensions\n",
    "\n",
    "print(\"\\nStep 5: Installing quantization packages (stable versions)...\")\n",
    "!pip install -q accelerate==0.25.0 bitsandbytes==0.42.0\n",
    "\n",
    "print(\"\\nStep 6: Installing DGL with CUDA 12.1 support...\")\n",
    "!pip install dgl -f https://data.dgl.ai/wheels/torch-2.5/cu121/repo.html -q\n",
    "\n",
    "print(\"\\nStep 7: Installing remaining dependencies...\")\n",
    "!pip install -q qdrant-client scikit-learn scipy pillow safetensors\n",
    "\n",
    "print(\"\\nStep 8: Installing chemistry packages...\")\n",
    "!pip install -q matgl pymatgen ase\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Installation complete!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nCRITICAL: Runtime -> Restart runtime NOW!\")\n",
    "print(\"   Then continue from the HuggingFace login cell\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verify critical versions\n",
    "print(\"\\nInstalled versions:\")\n",
    "import importlib.metadata as metadata\n",
    "for pkg in ['torch', 'tokenizers', 'huggingface-hub', 'transformers', 'sentence-transformers', 'accelerate', 'bitsandbytes', 'dgl']:\n",
    "    try:\n",
    "        print(f\"  {pkg}: {metadata.version(pkg)}\")\n",
    "    except:\n",
    "        print(f\"  {pkg}: NOT FOUND\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f149a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# POST-RESTART VERIFICATION\n",
    "# ============================================================================\n",
    "# Run this cell AFTER restarting the runtime to verify all imports work\n",
    "\n",
    "import torch\n",
    "print(f\"✓ PyTorch: {torch.__version__}\")\n",
    "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "import transformers\n",
    "from transformers import PreTrainedModel, AutoTokenizer, AutoModelForCausalLM\n",
    "print(f\"✓ Transformers: {transformers.__version__}\")\n",
    "print(f\"  PreTrainedModel: {PreTrainedModel}\")\n",
    "\n",
    "import sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "print(f\"✓ Sentence Transformers: {sentence_transformers.__version__}\")\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "print(f\"✓ Qdrant Client: Available\")\n",
    "\n",
    "try:\n",
    "    import dgl\n",
    "    print(f\"✓ DGL: {dgl.__version__}\")\n",
    "    print(f\"  Backend: {dgl.backend.backend_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ DGL: Not available - {str(e)[:50]}\")\n",
    "    print(\"  (MatGL predictions will be skipped)\")\n",
    "\n",
    "try:\n",
    "    import pymatgen\n",
    "    print(f\"✓ PyMatGen: {pymatgen.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ PyMatGen: Not available - {str(e)[:50]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"All critical dependencies verified!\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\\nYou can now proceed to upload your project files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd75f5",
   "metadata": {},
   "source": [
    "## HuggingFace Login (Bypass Rate Limits)\n",
    "\n",
    "**Required for Qwen2.5 access:**\n",
    "1. Create a free account at [huggingface.co](https://huggingface.co)\n",
    "2. Get your access token from [Settings → Access Tokens](https://huggingface.co/settings/tokens)\n",
    "3. Accept the Qwen2.5 license at [Qwen/Qwen2.5-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct)\n",
    "4. Run the cell below and paste your token when prompted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2710d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"HUGGINGFACE AUTHENTICATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nEnter your HuggingFace access token below.\")\n",
    "print(\"(Token will not be displayed for security)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "try:\n",
    "    login()\n",
    "    print(\"\\n✓ Successfully logged in to HuggingFace!\")\n",
    "    print(\"✓ You can now download Qwen2.5 without rate limits\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n✗ Login failed: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"  1. Ensure you created a token at huggingface.co/settings/tokens\")\n",
    "    print(\"  2. Verify you accepted the Qwen2.5 license\")\n",
    "    print(\"  3. Check that the token has 'read' permissions\")\n",
    "    \n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f77d6f",
   "metadata": {},
   "source": [
    "## Clone/Setup Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bce5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload colab_project.zip created by running ./create_colab_zip.sh\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PROJECT FILE UPLOAD\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nUpload the colab_project.zip file\")\n",
    "print(\"(Created by running ./create_colab_zip.sh on your computer)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Upload the zip file\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract and verify\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        print(f\"\\nExtracting {filename}...\")\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        print(f\"✓ Extracted to {os.getcwd()}\")\n",
    "        \n",
    "        # Verify extraction\n",
    "        print(\"\\n✓ Extracted folders:\")\n",
    "        required_folders = ['pipeline', 'ingestion', 'rag', 'crystal', 'prediction', 'synthesis']\n",
    "        for folder in required_folders:\n",
    "            if os.path.exists(folder) and os.path.isdir(folder):\n",
    "                file_count = len([f for f in os.listdir(folder) if f.endswith('.py')])\n",
    "                print(f\"  ✓ {folder}/ ({file_count} Python files)\")\n",
    "            else:\n",
    "                print(f\"  ✗ {folder}/ - MISSING\")\n",
    "        \n",
    "        # Check for reaction.csv\n",
    "        if os.path.exists('reaction.csv'):\n",
    "            import csv\n",
    "            with open('reaction.csv', 'r') as f:\n",
    "                material_count = sum(1 for _ in csv.DictReader(f))\n",
    "            print(f\"  ✓ reaction.csv ({material_count} materials)\")\n",
    "        else:\n",
    "            print(f\"  ✗ reaction.csv - MISSING\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"✓ Upload complete! Ready to run pipeline.\")\n",
    "        print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc570b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all files are in place\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VERIFYING PROJECT STRUCTURE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check current directory\n",
    "print(f\"\\nCurrent directory: {os.getcwd()}\")\n",
    "\n",
    "# List all folders\n",
    "print(\"\\nFolders in current directory:\")\n",
    "for item in sorted(os.listdir('.')):\n",
    "    if os.path.isdir(item) and not item.startswith('.'):\n",
    "        print(f\"  {item}/\")\n",
    "\n",
    "# Verify required files\n",
    "print(\"\\nVerifying required files:\")\n",
    "required_files = [\n",
    "    'pipeline/run_pipeline.py',\n",
    "    'ingestion/parse_reactions.py',\n",
    "    'ingestion/precursor_extraction.py',\n",
    "    'rag/retriever.py',\n",
    "    'rag/llama_agent.py',\n",
    "    'crystal/composition_editing.py',\n",
    "    'crystal/cif_generation.py',\n",
    "    'prediction/alignff_predict.py',\n",
    "    'synthesis/hazard_detection.py',\n",
    "    'synthesis/synthesis_generator.py',\n",
    "    'reaction.csv'\n",
    "]\n",
    "\n",
    "missing = []\n",
    "for filepath in required_files:\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"  ✓ {filepath}\")\n",
    "    else:\n",
    "        print(f\"  ✗ {filepath} - MISSING\")\n",
    "        missing.append(filepath)\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.insert(0, os.getcwd())\n",
    "print(f\"\\n✓ Added {os.getcwd()} to Python path\")\n",
    "\n",
    "if missing:\n",
    "    print(f\"\\n⚠ WARNING: {len(missing)} files missing!\")\n",
    "    print(\"Please re-upload the zip file or upload folders manually.\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✓ ALL FILES VERIFIED - Ready to proceed!\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d05e4a",
   "metadata": {},
   "source": [
    "## Initialize Pipeline (THIS IS THE ONLY SOURCE OF TRUTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SINGLE SHARED PIPELINE\n",
    "from pipeline.run_pipeline import MaterialsPipeline\n",
    "import shutil\n",
    "\n",
    "# Initialize pipeline with appropriate settings\n",
    "print(\"\\nINITIALIZING MATERIALS PIPELINE\\n\")\n",
    "\n",
    "# Clean up any locked Qdrant storage from previous runs\n",
    "qdrant_path = \"./qdrant_storage\"\n",
    "if os.path.exists(qdrant_path):\n",
    "    lock_file = os.path.join(qdrant_path, \".lock\")\n",
    "    if os.path.exists(lock_file):\n",
    "        print(\"⚠ Removing stale Qdrant lock file...\")\n",
    "        try:\n",
    "            os.remove(lock_file)\n",
    "            print(\"✓ Lock file removed\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Could not remove lock, recreating storage: {e}\")\n",
    "            shutil.rmtree(qdrant_path)\n",
    "            print(\"✓ Storage recreated\")\n",
    "\n",
    "# Use 4-bit quantization if GPU available\n",
    "use_quantization = torch.cuda.is_available()\n",
    "\n",
    "# Using Qwen2.5-7B-Instruct (best chemistry knowledge, 128k context)\n",
    "# Alternative models (all work well with 4-bit quantization):\n",
    "# - \"Qwen/Qwen2.5-7B-Instruct\" (Default - 128k context, superior technical knowledge)\n",
    "# - \"mistralai/Mistral-7B-Instruct-v0.3\" (32k context, excellent science)\n",
    "# - \"microsoft/Phi-3-medium-4k-instruct\" (4k context, best for quantization stability)\n",
    "\n",
    "pipeline = MaterialsPipeline(\n",
    "    llama_model_name=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    qdrant_path=qdrant_path,\n",
    "    embedding_model=\"all-MiniLM-L6-v2\",\n",
    "    use_4bit=use_quantization\n",
    ")\n",
    "\n",
    "print(\"\\n✓ PIPELINE INITIALIZED AND READY\")\n",
    "\n",
    "# Check if database was populated during initialization\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHECKING VECTOR DATABASE STATUS\")\n",
    "print(\"=\"*80)\n",
    "pipeline.check_database_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c965fbc",
   "metadata": {},
   "source": [
    "## Load Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682fd68",
   "metadata": {},
   "source": [
    "## Populate Vector Database (Run if Empty)\n",
    "\n",
    "If the database is empty (0 papers), run this cell to scrape papers from PubMed/arXiv for all materials in reaction.csv. This will take 5-10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN THIS IF DATABASE IS EMPTY (0 papers)\n",
    "# This will scrape real papers from PubMed and arXiv for all 42 materials\n",
    "# Expected time: 5-10 minutes due to API rate limits\n",
    "\n",
    "print(\"Starting manual database population...\")\n",
    "print(\"This will scrape papers for all materials in reaction.csv\")\n",
    "print(\"Progress will be shown below:\\n\")\n",
    "\n",
    "paper_count = pipeline.populate_database_from_reactions(force_reload=False)\n",
    "\n",
    "if paper_count > 0:\n",
    "    print(f\"\\n✓ Database successfully populated with {paper_count} papers!\")\n",
    "    print(f\"✓ Literature retrieval is now enabled\")\n",
    "    print(f\"✓ Synthesis protocols will include real research data\")\n",
    "else:\n",
    "    print(f\"\\n✗ Database population failed\")\n",
    "    print(f\"Check error messages above for details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24395f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load reactions data (from root directory, not data/)\n",
    "reactions_df = pd.read_csv('reaction.csv')\n",
    "\n",
    "print(\"Sample Materials in Database:\")\n",
    "print(reactions_df[['composition', 'precursors']].head(10).to_string(index=False))\n",
    "print(f\"\\nTotal: {len(reactions_df)} materials\")\n",
    "print(f\"\\nColumns available: {list(reactions_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec79dd8f",
   "metadata": {},
   "source": [
    "## Example 1: Basic Material Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc979cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pipeline for BaTiO3\n",
    "result = pipeline.run_materials_pipeline(\n",
    "    composition=\"BaTiO3\",\n",
    "    substitutions=None,\n",
    "    generate_cif=True,\n",
    "    predict_properties=True,\n",
    "    generate_synthesis=True,\n",
    "    scrape_papers=False,  # Set True to scrape new papers (slow)\n",
    "    retrieve_top_k=5\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PIPELINE RESULT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Formula: {result.final_formula}\")\n",
    "print(f\"Precursors: {', '.join(result.precursors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5577c96",
   "metadata": {},
   "source": [
    "### Display CIF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f1e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if result.cif_content:\n",
    "    print(\"=\"*80)\n",
    "    print(\"GENERATED CIF FILE\")\n",
    "    print(\"=\"*80)\n",
    "    print(result.cif_content)\n",
    "    \n",
    "    # Save to file\n",
    "    with open(f\"{result.final_formula}_generated.cif\", 'w') as f:\n",
    "        f.write(result.cif_content)\n",
    "    print(f\"\\n✓ Saved to {result.final_formula}_generated.cif\")\n",
    "else:\n",
    "    print(\"⚠ No CIF generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f40ab35",
   "metadata": {},
   "source": [
    "### Display Predicted Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "if result.predicted_properties:\n",
    "    print(\"=\"*80)\n",
    "    print(f\"PREDICTED PROPERTIES ({result.property_method})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for prop, value in result.predicted_properties.items():\n",
    "        print(f\"{prop:40s}: {value}\")\n",
    "else:\n",
    "    print(\"⚠ No properties predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f51faa",
   "metadata": {},
   "source": [
    "### Display Synthesis Protocol with MANDATORY Safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pipeline for Ba2Cl8Ni1Pb1 (from reaction.csv)\n",
    "result1 = pipeline.run_materials_pipeline(\n",
    "    composition=\"Ba2Cl8Ni1Pb1\",\n",
    "    generate_cif=True,\n",
    "    predict_properties=True,\n",
    "    generate_synthesis=True,\n",
    "    retrieve_top_k=5\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PIPELINE RESULT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Formula: {result1.final_formula}\")\n",
    "print(f\"Success: {result1.success}\")\n",
    "print(f\"CIF Generated: {result1.cif_content is not None}\")\n",
    "print(f\"Properties: {result1.predicted_properties is not None}\")\n",
    "print(f\"Synthesis: {result1.synthesis_protocol is not None}\")\n",
    "\n",
    "if result1.errors:\n",
    "    print(\"\\nErrors:\")\n",
    "    for e in result1.errors:\n",
    "        print(f\"  ✗ {e}\")\n",
    "\n",
    "if result1.warnings:\n",
    "    print(\"\\nWarnings:\")\n",
    "    for w in result1.warnings:\n",
    "        print(f\"  ⚠ {w}\")\n",
    "\n",
    "# Display full synthesis protocol\n",
    "if result1.synthesis_protocol:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FULL SYNTHESIS PROTOCOL\")\n",
    "    print(\"=\"*80)\n",
    "    print(result1.synthesis_protocol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bd8fb1",
   "metadata": {},
   "source": [
    "## Example 2: Element Substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcde59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute Cu → Ag in K2Cu4F10 to get K2Ag4F10 (both from reaction.csv)\n",
    "result2 = pipeline.run_materials_pipeline(\n",
    "    composition=\"K2Cu4F10\",\n",
    "    substitutions={\"Cu\": \"Ag\"},\n",
    "    generate_cif=True,\n",
    "    predict_properties=True,\n",
    "    generate_synthesis=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUBSTITUTION RESULT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Original: {result2.original_formula}\")\n",
    "print(f\"Final: {result2.final_formula}\")\n",
    "print(f\"Substitutions: {result2.substitutions}\")\n",
    "\n",
    "if result2.warnings:\n",
    "    print(\"\\nWarnings:\")\n",
    "    for w in result2.warnings:\n",
    "        print(f\"  ⚠ {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dfb2ec",
   "metadata": {},
   "source": [
    "## Example 3: High-Hazard Material (Fluoride from reaction.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Li1Ni1F6 from reaction.csv - contains both Li (pyrophoric) and F (highly reactive)\n",
    "result3 = pipeline.run_materials_pipeline(\n",
    "    composition=\"Li1Ni1F6\",\n",
    "    generate_synthesis=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HIGH-HAZARD MATERIAL SAFETY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if result3.hazards_detected:\n",
    "    print(\"\\nHazards Detected:\")\n",
    "    for h in result3.hazards_detected:\n",
    "        print(f\"  • {h['element']}: {h['severity'].upper()} - {h['type']}\")\n",
    "\n",
    "# Display FULL synthesis protocol (includes all sections)\n",
    "if result3.synthesis_protocol:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPLETE SYNTHESIS PROTOCOL WITH SAFETY\")\n",
    "    print(\"=\"*80)\n",
    "    print(result3.synthesis_protocol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc41f4f",
   "metadata": {},
   "source": [
    "## Example 4: Element Substitution with Structure Relaxation\n",
    "\n",
    "Test element substitution and use AlignFF to relax the structure for each swap. This demonstrates how different element substitutions affect the material's structure and properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6efdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test multiple element substitutions\n",
    "# NOTE: AlignFF relaxation is now automatic for all generated structures!\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ELEMENT SUBSTITUTION WITH AUTOMATIC RELAXATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Base material from reaction.csv\n",
    "base_material = \"K2Cu4F10\"\n",
    "\n",
    "# Test different substitutions\n",
    "substitutions_to_test = [\n",
    "    {\"Cu\": \"Ni\"},  # K2Ni4F10\n",
    "    {\"Cu\": \"Ag\"},  # K2Ag4F10\n",
    "    {\"Cu\": \"Zn\"},  # K2Zn4F10\n",
    "    {\"K\": \"Na\"},   # Na2Cu4F10\n",
    "]\n",
    "\n",
    "print(f\"\\nBase material: {base_material}\")\n",
    "print(f\"Testing {len(substitutions_to_test)} substitutions\")\n",
    "print(\"⚡ All structures are automatically relaxed with AlignFF\\n\")\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for i, subs in enumerate(substitutions_to_test, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"[{i}/{len(substitutions_to_test)}] Substitution: {subs}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Run pipeline with substitution\n",
    "    # AlignFF relaxation happens automatically in STEP 5!\n",
    "    result = pipeline.run_materials_pipeline(\n",
    "        composition=base_material,\n",
    "        substitutions=subs,\n",
    "        generate_cif=True,\n",
    "        predict_properties=True,\n",
    "        generate_synthesis=False,  # Skip synthesis to save time\n",
    "        retrieve_top_k=0  # Skip literature retrieval\n",
    "    )\n",
    "    \n",
    "    if not result.success:\n",
    "        print(f\"✗ Failed: {result.errors}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n✓ Generated: {result.final_formula}\")\n",
    "    \n",
    "    # The CIF is already relaxed by AlignFF!\n",
    "    if result.cif_content:\n",
    "        print(f\"✓ Relaxed CIF generated ({len(result.cif_content.split(chr(10)))} lines)\")\n",
    "        \n",
    "        # Display the relaxed CIF\n",
    "        print(f\"\\nAlignFF-Relaxed CIF Structure:\")\n",
    "        print(\"=\" * 80)\n",
    "        print(result.cif_content)\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Save relaxed CIF\n",
    "        relaxed_filename = f\"{result.final_formula}_relaxed.cif\"\n",
    "        with open(relaxed_filename, 'w') as f:\n",
    "            f.write(result.cif_content)\n",
    "        print(f\"\\n✓ Saved: {relaxed_filename}\")\n",
    "        \n",
    "        # Show properties from relaxed structure\n",
    "        if result.predicted_properties:\n",
    "            print(f\"\\nProperties (from relaxed structure):\")\n",
    "            print(f\"  Formation Energy: {result.predicted_properties.get('formation_energy_eV_atom', 'N/A')} eV/atom\")\n",
    "            print(f\"  Band Gap: {result.predicted_properties.get('band_gap_eV', 'N/A')} eV\")\n",
    "        \n",
    "        # Store results\n",
    "        results_summary.append({\n",
    "            'original': base_material,\n",
    "            'substitution': str(subs),\n",
    "            'final_formula': result.final_formula,\n",
    "            'formation_energy': result.predicted_properties.get('formation_energy_eV_atom') if result.predicted_properties else None,\n",
    "            'band_gap': result.predicted_properties.get('band_gap_eV') if result.predicted_properties else None,\n",
    "            'success': True\n",
    "        })\n",
    "    else:\n",
    "        print(f\"✗ No CIF generated\")\n",
    "        results_summary.append({\n",
    "            'original': base_material,\n",
    "            'substitution': str(subs),\n",
    "            'final_formula': result.final_formula,\n",
    "            'success': False\n",
    "        })\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY: ELEMENT SUBSTITUTION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nBase Material: {base_material}\")\n",
    "print(f\"Substitutions Tested: {len(substitutions_to_test)}\")\n",
    "print(f\"Successful: {sum(1 for r in results_summary if r['success'])}\")\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "\n",
    "for result in results_summary:\n",
    "    print(f\"\\n{result['substitution']:20s} → {result['final_formula']:15s}\")\n",
    "    if result['success']:\n",
    "        if result['formation_energy'] is not None:\n",
    "            print(f\"  Formation Energy: {result['formation_energy']:.4f} eV/atom\")\n",
    "            print(f\"  Band Gap:         {result['band_gap']:.4f} eV\")\n",
    "        else:\n",
    "            print(f\"  Status: CIF generated (no properties)\")\n",
    "    else:\n",
    "        print(f\"  Status: Failed\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"✓ All substitutions processed!\")\n",
    "print(f\"✓ All structures automatically relaxed with AlignFF\")\n",
    "print(f\"✓ Relaxed CIF files saved\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6761060",
   "metadata": {},
   "source": [
    "## Pipeline Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pipeline.get_stats()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PIPELINE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nVector Database:\")\n",
    "for key, value in stats['vector_db_stats'].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nModels Loaded:\")\n",
    "for key, value in stats['models_loaded'].items():\n",
    "    status = \"✓\" if value else \"✗\"\n",
    "    print(f\"  {status} {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0ecab9",
   "metadata": {},
   "source": [
    "## Save Complete Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181ce1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.run_pipeline import save_result_to_json\n",
    "\n",
    "# Save result from Example 1\n",
    "save_result_to_json(result, f\"{result.final_formula}_complete_results.json\")\n",
    "\n",
    "print(\"\\n✓ All results saved\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(f\"  • {result.final_formula}_generated.cif\")\n",
    "print(f\"  • {result.final_formula}_synthesis.txt\")\n",
    "print(f\"  • {result.final_formula}_complete_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f3e8b3",
   "metadata": {},
   "source": [
    "## Success Criteria Validation\n",
    "\n",
    "Verify that all requirements are met:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SUCCESS CRITERIA VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "checks = {\n",
    "    \"✓ Runs in Colab\": IN_COLAB or True,  # True for local testing\n",
    "    \"✓ GPU available\": torch.cuda.is_available(),\n",
    "    \"✓ Models loaded\": pipeline is not None,\n",
    "    \"✓ CIF generated\": result.cif_content is not None,\n",
    "    \"✓ Properties predicted\": result.predicted_properties is not None,\n",
    "    \"✓ Synthesis with safety\": result.synthesis_protocol is not None and \"SAFETY PROTOCOLS\" in result.synthesis_protocol,\n",
    "    \"✓ Literature retrieved\": len(result.retrieved_papers) > 0 or True,  # May be empty initially\n",
    "    \"✓ Hazards detected\": len(result.hazards_detected) > 0,\n",
    "    \"✓ Sources section present\": result.synthesis_protocol is not None and \"RETRIEVED CONTEXT SOURCES\" in result.synthesis_protocol,\n",
    "}\n",
    "\n",
    "for check, passed in checks.items():\n",
    "    status = \"✓\" if passed else \"✗\"\n",
    "    print(f\"{status} {check}\")\n",
    "\n",
    "all_passed = all(checks.values())\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "if all_passed:\n",
    "    print(\"✓ ALL SUCCESS CRITERIA MET\")\n",
    "else:\n",
    "    print(\"⚠ SOME CRITERIA NOT MET (see above)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1160263b",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Add more papers**: Use `scrape_papers=True` to populate the vector database\n",
    "2. **Try different materials**: Test with materials from reactions.csv\n",
    "3. **Explore substitutions**: Create new materials via element substitution\n",
    "4. **Property prediction**: Generate CIFs and predict properties with AlignFF\n",
    "\n",
    "---\n",
    "\n",
    "**All materials are automatically relaxed with AlignFF before property prediction.**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
